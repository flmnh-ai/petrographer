---
title: "Petrographic Image Analysis with Detectron2 and SAHI"
format: html
params:
  single_image: "data/raw/Lyons_data/c/139-45_xp_000019.jpg"
  batch_input_dir: "data/raw/Lyons_data/c"
  output_dir: "results"
  use_slicing: TRUE
  slice_size: 512
  overlap_ratio: 0.2
  confidence: 0.5
  device: "cpu"
---

**Main analysis workflow** for petrographic thin section images using Detectron2 with SAHI. This notebook provides a complete pipeline from model evaluation to morphological analysis with clean R-Python integration.

**Key Features:**

-   Python-based ML with Detectron2 + SAHI for detection
-   R-based analysis and visualization with tidyverse
-   Clean interface through modular R functions
-   Comprehensive morphological property analysis

## Setup

```{r setup, message=FALSE}
library(magick)
library(tidyverse)
library(scico)
library(patchwork)
library(glue)
library(cli)
library(fs)
library(petrographer)

# Configuration
config <- list(
  single_image = params$single_image,
  batch_input_dir = params$batch_input_dir,
  output_dir = params$output_dir,
  use_slicing = params$use_slicing,
  slice_size = params$slice_size,
  overlap_ratio = params$overlap_ratio,
  confidence = params$confidence,
  device = params$device
)

# Create output directory
dir_create(config$output_dir)

cli_h1("Analysis Configuration")
cli_dl(config[!names(config) %in% c("batch_input_dir")])
```

## Analysis Functions

We now use the optimized functions from `petrography_simple.R` which separate model loading from prediction for maximum efficiency. The model is loaded once and reused across all predictions.

```{r show-functions}
cli_h2("Available Analysis Functions")
cli_ul(c(
  "load_model() - Load detection model once for reuse",
  "predict_image() - Analyze single image with loaded model", 
  "predict_batch() - Process multiple images efficiently",
  "evaluate_training() - Assess model performance",
  "enhance_results() - Add derived metrics",
  "summarize_by_image() - Per-image statistics",
  "get_population_stats() - Overall population metrics"
))
```

## Model Loading

Load the trained detection model once for efficient reuse across all predictions.

```{r load-model}
cli_h2("Loading Model")

# Load the detection model with optimized settings
model <- load_model(
  confidence = config$confidence,
  device = config$device
)

cli_alert_success("Model loaded successfully")
cli_dl(c(
  "Model path" = path_file(model$model_path),
  "Config path" = path_file(model$config_path), 
  "Confidence threshold" = model$confidence,
  "Device" = model$device
))
```

## Model Training Evaluation

Evaluate the performance of our trained model by analyzing training logs.

```{r training-evaluation}
cli_h2("Training Evaluation")

# Run training evaluation
eval_result <- evaluate_training()

cli_h3("Evaluation Summary")
cli_dl(c(
  "Output directory" = eval_result$output_dir,
  "Metrics available" = eval_result$summary$metrics_available,
  "Training data records" = nrow(eval_result$training_data),
  "Total iterations" = eval_result$summary$total_iterations
))

# Final metrics from training data
if (nrow(eval_result$training_data) > 0) {
  training_df <- eval_result$training_data
  final_loss <- tail(training_df$total_loss[!is.na(training_df$total_loss)], 1)
  final_lr <- tail(training_df$lr[!is.na(training_df$lr)], 1)
  
  cli_h3("Final Training Metrics")
  cli_dl(c(
    "Final total loss" = round(final_loss, 4),
    "Final learning rate" = format(final_lr, scientific = TRUE)
  ))
}
```

Display training curves and evaluation metrics.

```{r training-plots, fig.width=12, fig.height=8}
# Training loss curves
training_df <- eval_result$training_data
loss_cols <- training_df %>% 
  select(contains("loss")) %>% 
  names()

p_loss <- training_df %>%
  select(iteration, all_of(loss_cols)) %>%
  pivot_longer(cols = -iteration, names_to = "loss_type", values_to = "loss_value") %>%
  filter(!is.na(loss_value)) %>%
  ggplot(aes(x = iteration, y = loss_value, color = loss_type)) +
  geom_line() +
  facet_wrap(~loss_type, scales = "free_y") +
  labs(title = "Training Loss Curves", x = "Iteration", y = "Loss") +
  theme_minimal() +
  theme(legend.position = "none")

print(p_loss)

# Learning rate schedule
p_lr <- training_df %>%
  filter(!is.na(lr)) %>%
  ggplot(aes(x = iteration, y = lr)) +
  geom_line(color = "blue") +
  scale_y_log10() +
  labs(title = "Learning Rate Schedule", x = "Iteration", y = "Learning Rate (log)") +
  theme_minimal()

print(p_lr)
```

## Single Image Analysis

Demonstrate detailed analysis on a single image.

```{r single-image-analysis}
cli_h2("Single Image Analysis")

# Run prediction on single image using loaded model
single_result <- predict_image(
  image_path = config$single_image,
  model = model,
  use_slicing = config$use_slicing,
  slice_size = config$slice_size,
  overlap = config$overlap_ratio,
  output_dir = path(config$output_dir, "single_image")
)

cli_alert_info("Image analyzed: {path_file(config$single_image)}")
cli_alert_success("Objects detected: {nrow(single_result)}")
```

```{r single-image-display, fig.width=30, fig.height=12}
# Original image
original_img <- image_read(config$single_image)

# Prediction image
pred_files <- dir_ls(path(config$output_dir, "single_image"), 
                    regexp = "*_prediction.png")

if (length(pred_files) > 0) {
  pred_img <- image_read(pred_files[1])
  
  # Display side by side
  combined <- image_append(c(original_img, pred_img))
  par(mar = c(0, 0, 0, 0))
  plot(combined)
} else {
  cli_alert_warning("No prediction images found")
}
```

Analyze morphological properties of detected objects.

```{r single-image-morphology}
cli_h3("Morphological Analysis")

if (nrow(single_result) > 0) {
  # Display summary statistics
  morph_stats <- get_population_stats(single_result)
  
  cli_dl(c(
    "Objects detected" = nrow(single_result),
    "Total area" = glue("{round(morph_stats$total_area)} pixels"),
    "Mean area" = glue("{round(morph_stats$mean_area)} pixels"),
    "Mean circularity" = round(morph_stats$mean_circularity, 3),
    "Mean eccentricity" = round(morph_stats$mean_eccentricity, 3)
  ))
} else {
  cli_alert_info("No objects detected for morphological analysis")
}
  
# Interactive data table
single_result %>%
  mutate(across(where(is.numeric), ~round(.x, 1)))
```

Create morphological analysis plots.

```{r single-morphology-plots, fig.width=12, fig.height=10}
if (nrow(single_result) > 0) {
  # Size distribution
  p1 <- single_result %>%
    ggplot(aes(x = area)) +
    geom_histogram(bins = 20, fill = "steelblue", alpha = 0.7) +
    scale_x_log10() +
    labs(title = "Particle Size Distribution", x = "Area (log scale)", y = "Count") +
    theme_minimal()

  # Eccentricity distribution
  p2 <- single_result %>%
    ggplot(aes(x = eccentricity)) +
    geom_histogram(bins = 20, fill = "coral", alpha = 0.7) +
    labs(title = "Eccentricity Distribution", x = "Eccentricity", y = "Count") +
    theme_minimal()

  # Orientation distribution
  p3 <- single_result %>%
    ggplot(aes(x = orientation_deg)) +
    geom_histogram(bins = 20, fill = "forestgreen", alpha = 0.7) +
    labs(title = "Orientation Distribution", x = "Orientation (degrees)", y = "Count") +
    theme_minimal()

  # Circularity vs Area
  p4 <- single_result %>%
    ggplot(aes(x = area, y = circularity)) +
    geom_point(alpha = 0.6) +
    scale_x_log10() +
    labs(title = "Circularity vs Size", x = "Area (log scale)", y = "Circularity") +
    theme_minimal()

  # Combine plots
  (p1 + p2) / (p3 + p4)
} else {
  cli_alert_info("No data available for morphological plots")
}
```

## Batch Processing

Process multiple images and analyze population statistics.

```{r batch-processing}
cli_h2("Batch Processing")

# Create a temp directory with a few images for demo
temp_batch_dir <- path(config$output_dir, "temp_batch_input")
dir_create(temp_batch_dir)

# Find and copy first few images for demo
all_images <- dir_ls(config$batch_input_dir, 
                    regexp = "(?i)\\.(jpg|jpeg|png|tiff|tif)$")

# Copy first 5 images to temp directory
demo_images <- head(all_images, 5)
for (img in demo_images) {
  file_copy(img, temp_batch_dir)
}

cli_alert_info("Copied {length(demo_images)} images for batch demo")

# Run batch prediction using loaded model
batch_result <- predict_batch(
  input_dir = temp_batch_dir,
  model = model,
  use_slicing = config$use_slicing,
  slice_size = config$slice_size,
  overlap = config$overlap_ratio,
  output_dir = path(config$output_dir, "batch_results"),
  save_visualizations = TRUE
)

cli_h3("Batch Processing Results")
cli_dl(c(
  "Images processed" = length(unique(batch_result$image_name)),
  "Total objects detected" = nrow(batch_result),
  "Output directory" = path(config$output_dir, "batch_results")
))
```

Analyze batch results and population statistics.

```{r batch-analysis}
cli_h3("Population Analysis")

if (nrow(batch_result) > 0) {
  # Population statistics
  pop_stats <- get_population_stats(batch_result)
  
  cli_dl(c(
    "Total images processed" = pop_stats$unique_images,
    "Total objects detected" = pop_stats$total_objects,
    "Average objects per image" = round(pop_stats$mean_objects_per_image, 1),
    "Total area detected" = glue("{round(pop_stats$total_area)} pixels"),
    "Mean object area" = glue("{round(pop_stats$mean_area)} pixels")
  ))

  # Summary statistics by image using package function
  batch_summary <- summarize_by_image(batch_result)
  
  # Display summary table
  batch_summary %>%
    mutate(across(where(is.numeric), ~round(.x, 3)))
} else {
  cli_alert_info("No batch data available for analysis")
}
```

Create population-level visualizations.

```{r batch-visualizations, fig.width=14, fig.height=12}
if (nrow(batch_result) > 0) {
  # Population size distribution
  p1 <- batch_result %>%
    ggplot(aes(x = area)) +
    geom_histogram(bins = 30, fill = "steelblue", alpha = 0.7) +
    scale_x_log10() +
    labs(title = "Population Size Distribution", 
         x = "Area (log scale)", y = "Count") +
    theme_minimal()

  # Size distribution by image
  p2 <- batch_result %>%
    ggplot(aes(x = area, fill = image_name)) +
    geom_density(alpha = 0.5) +
    scale_x_log10() +
    labs(title = "Size Distribution by Image", 
         x = "Area (log scale)", y = "Density") +
    theme_minimal() +
    theme(legend.position = "none")

  # Morphological properties correlation
  p3 <- batch_result %>%
    slice_sample(n = min(500, nrow(batch_result))) %>%  # Sample for performance
    ggplot(aes(x = eccentricity, y = circularity, color = log10(area))) +
    geom_point(alpha = 0.6) +
    scale_color_viridis_c() +
    labs(title = "Morphological Properties", 
         x = "Eccentricity", y = "Circularity", 
         color = "Log Area") +
    theme_minimal()

  # Box plots by image
  p4 <- batch_result %>%
    ggplot(aes(x = image_name, y = area)) +
    geom_boxplot(alpha = 0.7) +
    scale_y_log10() +
    labs(title = "Size Distribution by Image", 
         x = "Image", y = "Area (log scale)") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Combine plots
  (p1 + p2) / (p3 + p4)
} else {
  cli_alert_info("No batch data available for visualization")
}
```

## Summary

Complete analysis workflow using modern R and Python integration for petrographic image analysis.
