---
title: "Inclusions Detection Model Training"
format: html
params:
  data_dir: "../../data/processed/inclusions"
  output_name: "inclusions_v2"
  num_classes: 2
  max_iter: 500
  learning_rate: 0.00025
  device: "cuda"
  eval_period: 100
  hpc_host: "hpg"
  hpc_user: "nicolas.gauthier"
---

Training **inclusions detection** model for petrographic analysis with extended training (4000 iterations).

## Setup

```{r setup, message=FALSE}
library(tidyverse)
library(fs)
library(here)
library(petrographer)

# Configuration
config <- list(
  data_dir = params$data_dir,
  output_name = params$output_name,
  num_classes = params$num_classes,
  max_iter = params$max_iter,
  learning_rate = params$learning_rate,
  device = params$device,
  eval_period = params$eval_period,
  hpc_host = if(params$hpc_host == "NULL") NULL else params$hpc_host,
  hpc_user = params$hpc_user,
  hpc_base_dir = "/blue/nicolas.gauthier/nicolas.gauthier",
  rsync_mode = "mirror",
  dry_run = FALSE
)

cat("\n=== Training Configuration ===\n")
for(name in names(config)) {
  if(name != "hpc_base_dir") {
    cat(sprintf("%s: %s\n", name, config[[name]]))
  }
}
```

## Training

```{r training}
# Validate dataset and train model
validate_dataset(config$data_dir)

# Train model
model_path <- do.call(train_model, config)
```

## Evaluation

```{r evaluation}
# Load training metrics
eval_result <- evaluate_training(model_dir = model_path)
summary_stats <- eval_result$summary
```

## Visualization

```{r plots, fig.width=10, fig.height=6}
if (nrow(eval_result$training_data) > 0) {
  # Simple training curves
  training_df <- eval_result$training_data
  
  # Loss plot
  loss_plot <- training_df |>
    select(iteration, contains("loss")) |>
    pivot_longer(-iteration, names_to = "loss_type", values_to = "loss") |>
    filter(!is.na(loss)) |>
    ggplot(aes(iteration, loss, color = loss_type)) +
    geom_line() +
    facet_wrap(~loss_type, scales = "free_y") +
    labs(title = glue::glue("Training Loss - {config$output_name}")) +
    theme_minimal() +
    theme(legend.position = "none")
  
  print(loss_plot)
  
  # Validation metrics if available
  if ("validation_data" %in% names(eval_result) && nrow(eval_result$validation_data) > 0) {
    val_plot <- eval_result$validation_data |>
      pivot_longer(-iteration, names_to = "metric", values_to = "value") |>
      filter(!is.na(value)) |>
      ggplot(aes(iteration, value)) +
      geom_line() +
      geom_point(size = 0.5) +
      facet_wrap(~metric, scales = "free_y") +
      labs(title = glue::glue("Validation Metrics - {config$output_name}")) +
      theme_minimal()
    
    print(val_plot)
  }
}
```

## Model Testing

```{r testing}
cat("\n== Testing Model ==\n")

# Load trained model
model <- load_model(
  model_path = path(model_path, "model_final.pth"),
  config_path = path(model_path, "config.yaml"),
  device = config$device
)

# Test on validation sample
val_images <- dir_ls(path(config$data_dir, "val"), 
                        regexp = "(?i)\\.(jpg|jpeg|png)$")

test_image <- val_images[1]

test_result <- predict_image(
  image_path = test_image,
  model = model,
  output_dir = here::here("results", paste0(config$output_name, "_test"))
)

cat(sprintf("Test image: %s\n", path_file(test_image)))
cat(sprintf("Objects detected: %d\n", nrow(test_result)))
cat(sprintf("Mean confidence: %.3f\n", mean(test_result$confidence)))
```

```{r}
library(magick)
list.files(here::here("results", paste0(config$output_name, "_test")), full.names = TRUE)[[1]] |>
image_read() |>
  plot()
```

## Summary

```{r summary}
cat("\n== Training Summary ==\n")

if (exists("test_result") && nrow(test_result) > 0) {
  cat(sprintf("Model successfully tested with %d detections\n", nrow(test_result)))
}
```
