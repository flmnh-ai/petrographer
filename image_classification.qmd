---
title: "Image Classification"
format: html
editor: visual
---

## Setup

```{r setup}
#reticulate::use_miniconda('r-reticulate')
#library(tensorflow)
library(keras3)
library(tfdatasets)
library(reticulate)
#keras3::install_keras(gpu = TRUE, backend = 'tensorflow')
#library(tfdatasets)
library(here)

# path to image data
image_dir <- here('data/Lyons_data') 
```

## Data import

```{r}
image_size <- c(512L, 512L)
batch_size <- 16

image_data <- image_dataset_from_directory(
    image_dir,
    label_mode = 'categorical',
    validation_split = 0.2,
    subset = "both",
    seed = 1337,
    interpolation = 'nearest',
    image_size = image_size,
    batch_size = batch_size,
)

train_ds <- image_data[[1]]
val_ds <- image_data[[2]]
```

```{r}
# Prefetching samples in GPU memory helps maximize GPU utilization.
train_ds %<>% dataset_prefetch()
val_ds   %<>% dataset_prefetch()
```

```{r}
batch <- train_ds %>%
  as_iterator() %>%
  iter_next()

str(batch)
```

```{r}
c(images, labels) %<-% batch
```

```{r}
display_image_tensor <- function(x, ..., max = 255,
                                 plot_margins = c(0, 0, 0, 0)) {
  if(!is.null(plot_margins))
    par(mar = plot_margins)

  x %>%
    as.array() %>%
    drop() %>%
    as.raster(max = max) %>%
    plot(..., interpolate = FALSE)
}

par(mfrow = c(3, 3))
for (i in 1:9)
  display_image_tensor(images[i,,,],
                       plot_margins = rep(.5, 4))
```

## Model specification

```{r}
conv_base <- application_vgg16(weights = 'imagenet', 
                               include_top = FALSE,
                               input_shape = c(512L, 512L, 3L))
```

```{r}
summary(conv_base)
```

```{r}
model <-  keras_model_sequential(input_shape = c(image_size, 3)) %>%
  layer_rescaling(1./255) %>%
  conv_base() %>%
  layer_global_average_pooling_2d() %>%
  layer_dense(units = 1024, activation = 'relu') %>%
  layer_dense(units = 512, activation = 'relu') %>%
  layer_dense(units = 5, activation = 'softmax')
```

```{r}
summary(model)
```

```{r}
length(model$trainable_weights)
```

```{r}
plot(model)
```

## Transfer learning

Freeze the convolutional base so we can just train the classifier.

```{r}
freeze_weights(conv_base)
length(model$trainable_weights)
```

Calculate class weights to handle unbalanced classes

```{r}
class_counts <- list.files(image_dir, full.names = TRUE) %>%
  purrr::map(~length(list.files(.x))) %>% 
  setNames(0:4)

totals <- purrr::reduce(class_counts, sum)

class_weights <- purrr::map(class_counts, ~totals / .x)
min_weight <- min(unlist(class_weights))
class_weights <- purrr::map(class_weights, ~.x/min_weight)
class_weights
```

```{r}
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_adam(),
  metrics = c("accuracy")
)

history <- model %>% fit(
  train_ds,
  epochs = 10,
  class_weight = class_weights,
  validation_data = val_ds
)
```

```{r}
plot(history)
```

```{r}
model %>%
  evaluate(train_ds,
           val_ds) # should be test set ultimately
```

## Fine tuning

Not that necessary because the model already performs well!

```{r}
unfreeze_weights(conv_base, from = "block3_conv1")
```

```{r}
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_adam(learning_rate = 1e-5),
  metrics = c("accuracy")
)

history <- model %>% fit(
  train_ds,
  epochs = 10,
  class_weight = class_weights,
  validation_data = val_ds
)
```

```{r}
model %>%
  evaluate(train_ds,
           val_ds) 
```

## Evaluation

Compare the predicted and actual classes of the validation set using a confusion matrix

```{r}
# Initialize iterator
val_iterator <- as_iterator(val_ds)

# Initialize an empty list to store individual tibbles
results_list <- list()

# Loop through the batches
while (TRUE) {
  # Get the next batch
  batch <- iter_next(val_iterator)
  
  # Exit loop if there are no more batches
  if (is.null(batch)) {
    break
  }
  # Get the predictions for the current batch
  predicted <- model %>% 
    predict(batch[[1]]) %>%
    op_argmax() %>% as.array()
  
  # Get the actual labels for the current batch
  actual <- batch[[2]] %>% 
    op_argmax() %>% as.array()
  
  # Create a tibble for the current batch and add it to the list
  results_list[[length(results_list) + 1]] <- tibble::tibble(predicted = predicted, actual = actual)
}

# Combine all the tibbles into one
all_results <- dplyr::bind_rows(results_list)

# Calculate and display the confusion matrix
table(all_results)
```

Visualize how the model is learning.

```{r, fig.asp = 1, fig.height=20}
last_conv_layer <- get_layer(conv_base, 'block5_conv3')
last_conv_layer_model <- keras_model(conv_base$inputs, last_conv_layer$output)
classifier_input <- layer_input(batch_shape = last_conv_layer$output$shape)

x <- classifier_input
for (layer_name in c('global_average_pooling2d', 'dense_2', 'dense_1', 'dense')) { 
    x <- get_layer(model, layer_name)(x)
}
  
classifier_model <- keras_model(classifier_input, x)

plot_activations <- function(x, ...) {
  x <- as.array(x)
  if(sum(x) == 0)
    return(plot(as.raster("gray")))
  rotate <- function(x) t(apply(x, 2, rev))
  image(rotate(x), asp = 1, axes = FALSE, useRaster = TRUE, col = terrain.colors(256), ...)
}

grad_cam <- function(image){
  preprocessed_img <- image[tf$newaxis, , , ] / 255
  
  with (tf$GradientTape() %as% tape, {
    last_conv_layer_output <- last_conv_layer_model(preprocessed_img)
    tape$watch(last_conv_layer_output)
    preds <- classifier_model(last_conv_layer_output)
    top_pred_index <- tf$argmax(preds[1, ])
    top_class_channel <- preds[, top_pred_index, style = 'python']
    
    
    grads <- tape$gradient(top_class_channel, last_conv_layer_output)
    
    pooled_grads <- mean(grads, axis = c(1,2,3), keepdims = TRUE)
    
    heatmap <-
      (last_conv_layer_output * pooled_grads) %>%
      mean(axis = -1) %>%
      .[1,,]
    
    pal <- hcl.colors(256, palette = 'Spectral', alpha = 0.25, rev = TRUE)
    heatmap <- as.array(heatmap)
    heatmap[] <- pal[cut(heatmap, 256)]
    heatmap <- as.raster(heatmap)
    
    display_image_tensor(image);rasterImage(heatmap, 0, 0, ncol(image), nrow(image), interpolate = FALSE)
  })
}

batch <- val_ds %>% as_iterator() %>% iter_next()

par(mfrow = c(3, 3))
purrr::walk(1:9, ~grad_cam(batch[[1]][.x,,,]))
purrr::walk(1:9, ~display_image_tensor(batch[[1]][.x,,,]))
```
